{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint \n",
    "import simplejson as json\n",
    "import http.client\n",
    "import pandas as pd\n",
    "from time import time, mktime\n",
    "from datetime import datetime, date, timedelta, time\n",
    "import arrow\n",
    "from pandas.io import sql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'grant_type': 'password', \n",
    "        'client_id': '[ENTER CLIENT ID HERE]', \n",
    "        'client_secret': '[ENTER CLIENT SECRET HERE]', \n",
    "        'username': '[ENTER USERNAME HERE]', \n",
    "        'password': '[ENTER PASSWORD HERE]'}\n",
    "result = requests.post('https://api.socialstudio.radian6.com/oauth/token', data=data)\n",
    "\n",
    "load = json.loads(result.content)\n",
    "key = load['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a midnight timestamp based on today's date:\n",
    "midnight = datetime.combine(date.today(), time.min)\n",
    "#create a time stamp value for yesterday at 00:00:00 hours:\n",
    "yesterday_midnight = midnight - timedelta(days=1)\n",
    "#create a time stamp value for yesterday at 23:59:00 hours, before midnight hits:\n",
    "yesterday_beforemidnight = midnight - timedelta(minutes=1)\n",
    "\n",
    "#below variable converts 'yesterday_midnight' into unix time\n",
    "sec_since_epochy = mktime(yesterday_midnight.timetuple()) + yesterday_midnight.microsecond/1000000.0\n",
    "#below code converts the 'sec_since_epochy' into epoch milliseconds, since it's the only timestamp social studio accepts\n",
    "startDate = int(sec_since_epochy * 1000)\n",
    "\n",
    "#below variable converts 'yesterday_beforemidnight' into unix time\n",
    "sec_since_epochb = mktime(yesterday_beforemidnight.timetuple()) + yesterday_beforemidnight.microsecond/1000000.0\n",
    "#below code converts the 'sec_since_epochb' into epoch milliseconds, since it's the only timestamp social studio accepts\n",
    "endDate = int(sec_since_epochb * 1000)\n",
    "\n",
    "#startDate and endDate are converted into strings wich is the only datatype the query string accepts\n",
    "startDate = str(startDate)\n",
    "endDate = str(endDate)\n",
    "\n",
    "headers = {\"access_token\": key}\n",
    "#we integrated the python variable strings startDate and endDate into the http query string below to query data \n",
    "#from the previous dat in an automated fashion\n",
    "url = 'https://api.socialstudio.radian6.com/v3/posts?topics=1135449&\\\n",
    "startDate=' + startDate + '&endDate=' + endDate + '&limit=1000'\n",
    "#as you can see, the http query string below has epoch milliseconds as a startDate and endDate\n",
    "#url = 'https://api.socialstudio.radian6.com/v3/posts?topics=1135449&startDate=1506927600000&endDate=1507013940000&limit=1000'\n",
    "resp = requests.get(url, headers=headers)\n",
    "Json = json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOPICS,ASSIGNED_USER,ARTICLE_ID,EXTERNAL_ID,HEADLINE,AUTHOR,\\\n",
    "CONTENT,ARTICLE_URL,MEDIA_PROVIDER,REGION,LANGUAGE,POST_STATUS,\\\n",
    "PUBLISH_DATE,HARVESTED_DATE,SENTIMENT,CLASSIFICATION,TAGS=\\\n",
    "[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "\n",
    "for data in Json['data']:\n",
    "    TOPICS.append(data['topics']),\n",
    "    ASSIGNED_USER.append(data['assignedUser']),\n",
    "    ARTICLE_ID.append(data['id']),\n",
    "    EXTERNAL_ID.append(data['externalId'])\n",
    "    HEADLINE.append(data['title']),\n",
    "    AUTHOR.append(data['author']['title']),\n",
    "    CONTENT.append(data['content']),\n",
    "    ARTICLE_URL.append(data['externalLink']),\n",
    "    MEDIA_PROVIDER.append(data['mediaProvider']['title']),\n",
    "    REGION.append(data['source']['region']),\n",
    "    LANGUAGE.append(data['source']['language']),\n",
    "    POST_STATUS.append(data['postStatus']),\n",
    "    PUBLISH_DATE.append(data['publishedDate']),\n",
    "    HARVESTED_DATE.append(data['harvestDate']),\n",
    "    SENTIMENT.append(data['sentiment'][0]['value']),\n",
    "    CLASSIFICATION.append(data['classification']),\n",
    "    TAGS.append(data['tags'])\n",
    "    \n",
    "df = pd.DataFrame([TOPICS,ASSIGNED_USER,ARTICLE_ID,EXTERNAL_ID,HEADLINE,AUTHOR,CONTENT,ARTICLE_URL,\n",
    "                   MEDIA_PROVIDER,REGION,LANGUAGE,POST_STATUS,PUBLISH_DATE,HARVESTED_DATE,SENTIMENT,CLASSIFICATION,TAGS]).T\n",
    "\n",
    "#Below code will produce a timestamp of when the API data was requested\n",
    "utc = arrow.utcnow()\n",
    "df['PullTime'] = utc.to('US/Pacific')\n",
    "\n",
    "\n",
    "#Below renames the columns\n",
    "df1= df.rename(columns={0: 'TOPICS',1: 'ASSIGNED_USER', 2: 'ARTICLE_ID', 3: 'EXTERNAL_ID', 4: 'HEADLINE',\n",
    "                        5: 'AUTHOR',6: 'CONTENT',7: 'ARTICLE_URL',8: 'MEDIA_PROVIDER',9: 'REGION',\n",
    "                        10: 'LANGUAGE',11: 'POST_STATUS',12: 'PUBLISH_DATE',13: 'HARVESTED_DATE',\n",
    "                        14: 'SENTIMENT',15: 'CLASSIFICATION',16: 'TAGS'})\n",
    "\n",
    "#Below transforms the TAGS feature into a string\n",
    "df1['TAGS'] = df1['TAGS'].astype(str)\n",
    "\n",
    "\n",
    "postDynamics = []\n",
    "for data in Json['data']:\n",
    "    postDynamics.append(data['postDynamics'])\n",
    "df2 = pd.DataFrame([postDynamics]).T\n",
    "df3 = df2.rename(columns={0:'List'})\n",
    "\n",
    "#The postDynamics feature was tricky, it had nested keys and values so I looped through the postDynamics key \n",
    "#and converted each nested list to a pandas.Series object with the label as the index This will result in a data frame \n",
    "#with the label as the column headers, and then you can concat with the remaining columns of the data frame to get what you need\n",
    "df4 = pd.concat([\n",
    "df3.drop('List', 1), \n",
    "    df3.List.apply(lambda lst: pd.Series({\n",
    "       d['label']: d['value'] for d in lst\n",
    "    }))\n",
    "], axis=1)\n",
    "\n",
    "df4 = df4.fillna(0)\n",
    "\n",
    "#Based on the transformation above, I concatenated df4 data frame with df1\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "\n",
    "\n",
    "#Insert pandas data frame, called 'result' into a mysql database\n",
    "\n",
    "db = create_engine('mysql+mysqldb://username:password@host:port/database?charset=utf8', \n",
    "                   echo=False, encoding = 'utf-8')\n",
    "cnx = db.connect()\n",
    "result.to_sql(name = 'ss_retrieve_posts', con= cnx, if_exists='append', index=False)\n",
    "cnx.close()\n",
    "db.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
